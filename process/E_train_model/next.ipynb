{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bd3ab8-81c7-4ded-b177-54c2570edb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T16:34:33.750101Z",
     "iopub.status.busy": "2023-02-05T16:34:33.749703Z",
     "iopub.status.idle": "2023-02-05T16:34:49.620846Z",
     "shell.execute_reply": "2023-02-05T16:34:49.619993Z",
     "shell.execute_reply.started": "2023-02-05T16:34:33.750026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n",
      "1.2.1\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp39-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /usr/lib/python3/dist-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.23.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.3)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.13.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.34.4)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, graphviz, plotly, catboost\n",
      "Successfully installed catboost-1.1.1 graphviz-0.20.1 plotly-5.13.0 tenacity-8.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    import time\n",
    "\n",
    "    import pandas as pd\n",
    "    #import streamlit as st\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "    import sklearn\n",
    "    print(sklearn.__version__)\n",
    "    #!pip install --upgrade scikit-learn\n",
    "    #!pip install --upgrade scipy\n",
    "    !pip install lightgbm\n",
    "    print(sklearn.__version__)\n",
    "\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "    DATA_VERSION = '11'\n",
    "\n",
    "\n",
    "    def get_columns(version: int) -> pd.DataFrame:\n",
    "        version_number = int(version)\n",
    "\n",
    "        if version_number == 2:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom, wildcard = [], []\n",
    "\n",
    "        elif version_number == 3 or version_number == 4:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'latitude_deviation', 'longitude_deviation']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom, wildcard = [], []\n",
    "\n",
    "        elif version_number <= 6:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude',\n",
    "                      'latitude_deviation', 'longitude_deviation']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom, wildcard = [], []\n",
    "\n",
    "        elif version_number == 7:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude',\n",
    "                      'latitude_deviation', 'longitude_deviation']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom = ['listingHistory.listingUpdateReason']\n",
    "            wildcard = []\n",
    "        elif version_number == 8:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude',\n",
    "                      'latitude_deviation', 'longitude_deviation', 'keyFeatures']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom = ['listingHistory.listingUpdateReason']\n",
    "            wildcard = []\n",
    "        elif version_number in [9, 10, 11, 12]:\n",
    "            booleans = []\n",
    "            floats = ['bedrooms', 'bathrooms', 'nearestStation', 'location.latitude', 'location.longitude',\n",
    "                      'latitude_deviation', 'longitude_deviation']\n",
    "            categories = ['tenure.tenureType']\n",
    "            custom = []  # ['reduced_features']\n",
    "            wildcard = ['feature__']\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'no columns data available for version {version}')\n",
    "\n",
    "        columns = []\n",
    "        columns.extend(booleans)\n",
    "        columns.extend(floats)\n",
    "        columns.extend(categories)\n",
    "        columns.extend(custom)\n",
    "        # columns.extend(wildcard)\n",
    "\n",
    "        return (columns, booleans, floats, categories, custom, wildcard)\n",
    "\n",
    "\n",
    "\n",
    "    def tt_split(VERSION, df, RANDOM_STATE=101, LABEL='Price'):\n",
    "        debug_mode=False\n",
    "\n",
    "        columns, booleans, floats, categories, custom, wildcard = get_columns(version=VERSION)\n",
    "\n",
    "        for column in categories:\n",
    "            df = pd.concat([df, pd.get_dummies(df[column], prefix=column)], axis=1)\n",
    "            df.drop([column], axis=1, inplace=True)  # now drop the original column (you don't need it anymore),\n",
    "            if debug_mode:print(\"updated df!!!\")\n",
    "            if debug_mode:print(df.head(1))\n",
    "            if debug_mode:print(\"df.columns[1:]\", df.columns[1:])\n",
    "            feature_names_internal = df.columns[1:]\n",
    "            if debug_mode:print(\"returnable_columns\", feature_names_internal)\n",
    "\n",
    "        # features = df[df.columns[:-1]].values\n",
    "        features = df[df.columns[1:]].values\n",
    "        # features = df[FEATURES].values\n",
    "        labels = df[LABEL].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "\n",
    "        #print(\"feature_names_internal\", feature_names_internal)\n",
    "        return X_train, X_test, y_train, y_test, feature_names_internal\n",
    "\n",
    "\n",
    "    def load_standard_model(selected_model, directory='../../models_pretrained', model_type='standard'):\n",
    "        if model_type == 'standard':\n",
    "            model_path = f'{directory}/{selected_model}.pkl'\n",
    "            model = pickle.load(open(model_path, 'rb'))\n",
    "        elif model_type== 'neural':\n",
    "            # model = keras.models.load_model('models/NN')\n",
    "            # model = keras.models.load_model(f'models/{selected_model}')\n",
    "            full_path = f'{directory}/{selected_model}'\n",
    "            model = keras.models.load_model(full_path)\n",
    "            print(\"directory\", directory)\n",
    "            print(\"selected_model\", selected_model)\n",
    "            print(\"full_path\", full_path)\n",
    "            model.summary()\n",
    "            #raise ValueError('breakpoint')\n",
    "        else:\n",
    "            raise ValueError('type: ' + model_type)\n",
    "\n",
    "    def load_model(selected_model):\n",
    "        if selected_model == 'Stacked Model':\n",
    "            raise ValueError ('operate stacked model')\n",
    "        global DATA_VERSION, X_test, y_test, feature_names, previous_data_version\n",
    "        try:\n",
    "            # model_path = f'models_pretrained/{selected_model}.pkl'\n",
    "            # model = pickle.load(open(model_path, 'rb'))\n",
    "            #from functions_gh_presentation_and_launch import load_standard_model\n",
    "            model = load_standard_model(selected_model=selected_model, model_type='neural' if 'eural' in selected_model else 'standard')\n",
    "            DATA_VERSION = selected_model[-2:]\n",
    "            X_test, y_test, feature_names = this_test_data(VERSION=DATA_VERSION, test_data_only=True, cloud_or_webapp_run=True, versioned=True)\n",
    "        except:\n",
    "            # raise ValueError(f'failed to load model: {model_path}')\n",
    "            raise ValueError(f'failed to load model: {selected_model}')\n",
    "        return model\n",
    "\n",
    "\n",
    "    #from sklearn.metrics import PredictionErrorDisplay\n",
    "    from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "\n",
    "    #from functions_b__get_the_data_2023 import get_source_dataframe\n",
    "    #from functions_d3__prepare_store_data_2023 import this_test_data\n",
    "\n",
    "\n",
    "    def get_source_dataframe(cloud_or_webapp_run, version, row_limit=None, folder_prefix='../../../'):\n",
    "\n",
    "        filename = f'df_listings_v{version}.csv'\n",
    "        remote_pathname = f'https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/{filename}'\n",
    "        df_pathname_raw = folder_prefix + f'data/source/{filename}'\n",
    "        df_pathname_tidy = folder_prefix + f'data/final/{filename}'\n",
    "\n",
    "        if cloud_or_webapp_run:\n",
    "            df = pd.read_csv(remote_pathname, on_bad_lines='error', index_col=0)\n",
    "            retrieval_type = 'tidy'\n",
    "            print('loaded data from', folder_prefix + remote_pathname)\n",
    "        else:\n",
    "            df = pd.read_csv(df_pathname_tidy, on_bad_lines='error', index_col=0)\n",
    "            retrieval_type = 'tidy'\n",
    "            print('loaded data from', df_pathname_tidy)\n",
    "\n",
    "        if row_limit and row_limit > 0:\n",
    "            df = df[:row_limit]\n",
    "        return df, retrieval_type\n",
    "\n",
    "    !pip install catboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc678368-f955-4bb7-9651-6344bd3e01d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T16:39:28.630457Z",
     "iopub.status.busy": "2023-02-05T16:39:28.629515Z",
     "iopub.status.idle": "2023-02-05T16:39:30.920656Z",
     "shell.execute_reply": "2023-02-05T16:39:30.919472Z",
     "shell.execute_reply.started": "2023-02-05T16:39:28.630422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting test data for version 11\n",
      "ENDED UP IN GENERAL EXCEPTION train_test/feature_names_v11.csv not found.\n",
      "train_test/feature_names_v11.csv not found.\n",
      "loaded data from https://raw.githubusercontent.com/jayportfolio/capstone_streamlit/main/data/final/df_listings_v11.csv\n",
      "test_data_only True\n",
      "drop_nulls True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, None was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m scorers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     39\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 40\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscorers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(est, X, y, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:261\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    259\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m \u001b[43m_check_multimetric_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py:580\u001b[0m, in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Non-string types were found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the given list. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscoring\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             )\n\u001b[0;32m--> 580\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    581\u001b[0m         scorer: check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscorer) \u001b[38;5;28;01mfor\u001b[39;00m scorer \u001b[38;5;129;01min\u001b[39;00m scoring\n\u001b[1;32m    582\u001b[0m     }\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Empty list was given. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscoring\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py:581\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Non-string types were found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the given list. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscoring\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m             )\n\u001b[1;32m    580\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 581\u001b[0m         scorer: \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m scorer \u001b[38;5;129;01min\u001b[39;00m scoring\n\u001b[1;32m    582\u001b[0m     }\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Empty list was given. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscoring\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py:474\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"Determine scorer from user options.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03mA TypeError will be thrown if the estimator cannot be scored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    ``scorer(estimator, X, y)``.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator should be an estimator implementing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method, \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m was passed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;241m%\u001b[39m estimator\n\u001b[1;32m    477\u001b[0m     )\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scorer(scoring)\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, None was passed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x504 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "selected_model_key = 'Stacked Model' \n",
    "if True:\n",
    "    if selected_model_key == 'Stacked Model':\n",
    "        from sklearn.ensemble import StackingRegressor\n",
    "        from sklearn.linear_model import RidgeCV\n",
    "\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        modell = LinearRegression()\n",
    "        modell.fit(X_test, y_test)\n",
    "\n",
    "        estimators = [\n",
    "            ##(\"Random Forest1\", load_model('optimised_model_XG Boost (tree)_v10')),\n",
    "            ##(\"Random Forest2\", load_model('optimised_model_XG Boost (tree)_v10')),\n",
    "           # (\"Random Forest2\", load_model('optimised_model_CatBoost_v10(no dummies)_v10'))\n",
    "            #(\"Lasso\", lasso_pipeline),\n",
    "            #(\"Gradient Boosting\", gbdt_pipeline),\n",
    "\n",
    "            \n",
    "            (\"Random Forest1\", modell),\n",
    "            (\"Random Forest2\", modell),\n",
    "            (\"Random Forest3\", load_model('optimised_model_Linear Regression (Ridge)_v11')),\n",
    "        \n",
    "        ]\n",
    "\n",
    "        stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())\n",
    "        stacking_regressor\n",
    "\n",
    "        X = X_test\n",
    "        y = y_test\n",
    "\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n",
    "        axs = np.ravel(axs)\n",
    "\n",
    "        for ax, (name, est) in zip(\n",
    "                axs, estimators + [(\"Stacking Regressor\", stacking_regressor)]\n",
    "        ):\n",
    "            scorers = {\"R2\": \"r2\", \"MAE\": \"neg_mean_absolute_error\"}\n",
    "\n",
    "            start_time = time.time()\n",
    "            scores = cross_validate(\n",
    "                est, X, y, scoring=list(scorers.values()), n_jobs=-1, verbose=0\n",
    "            )\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            y_pred = cross_val_predict(est, X, y, n_jobs=-1, verbose=0)\n",
    "            scores = {\n",
    "                key: (\n",
    "                    f\"{np.abs(np.mean(scores[f'test_{value}'])):.2f} +- \"\n",
    "                    f\"{np.std(scores[f'test_{value}']):.2f}\"\n",
    "                )\n",
    "                for key, value in scorers.items()\n",
    "            }\n",
    "\n",
    "            #display = PredictionErrorDisplay.from_predictions(\n",
    "            #    y_true=y,\n",
    "            #    y_pred=y_pred,\n",
    "            #    kind=\"actual_vs_predicted\",\n",
    "            #    ax=ax,\n",
    "            #    scatter_kwargs={\"alpha\": 0.2, \"color\": \"tab:blue\"},\n",
    "            #    line_kwargs={\"color\": \"tab:red\"},\n",
    "            #)\n",
    "            ax.set_title(f\"{name}\\nEvaluation in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "            for name, score in scores.items():\n",
    "                ax.plot([], [], \" \", label=f\"{name}: {score}\")\n",
    "            ax.legend(loc=\"upper left\")\n",
    "\n",
    "        plt.suptitle(\"Single predictors versus stacked predictors\")\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "\n",
    "        selected_model = 'stacked model_v11'\n",
    "        model = stacking_regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e74ce1-d163-4c30-bb6c-12787d477c37",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-02-05T16:34:50.212835Z",
     "iopub.status.idle": "2023-02-05T16:34:50.213149Z",
     "shell.execute_reply": "2023-02-05T16:34:50.213018Z",
     "shell.execute_reply.started": "2023-02-05T16:34:50.213006Z"
    }
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "#X, y = load_diabetes(return_X_y=True)\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42))\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                           random_state=42)\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42\n",
    ")\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)\n",
    "\n",
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed8230e1-07b3-4a7f-af14-adfbd7b9e64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T19:43:34.382176Z",
     "iopub.status.busy": "2023-02-05T19:43:34.381626Z",
     "iopub.status.idle": "2023-02-05T20:08:12.089190Z",
     "shell.execute_reply": "2023-02-05T20:08:12.085454Z",
     "shell.execute_reply.started": "2023-02-05T19:43:34.382136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting test data for version 06\n",
      "getting test data for version 06\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 39714, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425241.939971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:43:49] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:46:04] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31771, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425307.563155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31771, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425367.997482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31771, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425176.388593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31771, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425304.504611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31772, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 425053.251951\n",
      "[19:49:32] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:51:21] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:53:14] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:55:05] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:56:57] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[19:58:50] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:00:44] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:02:34] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:04:28] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:06:17] WARNING: ../src/learner.cc:627: \n",
      "Parameters: { \"max_leaf_nodes\", \"max_samples\", \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6639179978620906"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "#X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "X_train, y_train, X_test, y_test, feature_names = this_test_data(VERSION='06', test_data_only=False, cloud_or_webapp_run=True, versioned=True)\n",
    "X_train, X_test, y_train, y_test, feature_names = this_test_data(VERSION='06', test_data_only=False, cloud_or_webapp_run=True, versioned=True)\n",
    "\n",
    "#model1 = Ridge('model__alpha': 1e-05, 'model__copy_X': False, 'model__fit_intercept': True, 'model__max_iter': 1000, 'model__positive': False, 'model__random_state': 101, 'model__solver': 'sag', 'model__tol': 0.001)\n",
    "model1 = Pipeline([\n",
    "        #('mms', MinMaxScaler()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('model', Ridge(alpha=1e-05,copy_X=False, fit_intercept=True, max_iter=1000,positive=False, random_state=101, solver='sag', tol=0.001))\n",
    "    ])\n",
    "model2 = Pipeline([\n",
    "        #('mms', MinMaxScaler()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('model',XGBRegressor())\n",
    "    ])\n",
    "model2.set_params(**{'model__booster': 'dart', 'model__colsample_bytree': 0.9, 'model__lambda': 1, 'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__max_features': None, 'model__max_leaf_nodes': 20, 'model__max_samples': 1, 'model__min_sample_split': None, 'model__min_samples_leaf': 2000, 'model__n_estimators': 500, 'model__n_jobs': 3, 'model__objective': 'reg:squarederror', 'model__subsample': 0.5, 'model__tree_method': 'hist', 'model__verbosity': 1})\n",
    "model3 = Pipeline([\n",
    "        #('mms', MinMaxScaler()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('model',KNeighborsRegressor())\n",
    "    ])\n",
    "#model3.set_params(**{'model__algorithm': 'brute', 'model__leaf_size': 300, 'model__metric': 'minkowski', 'model__n_jobs': 2, 'model__n_neighbors': 13, 'model__p': 1, 'model__weights': 'distance'})\n",
    "#model3.set_params(**{})\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "model4 = Pipeline([\n",
    "        #('mms', MinMaxScaler()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('model',LGBMRegressor())\n",
    "    ])\n",
    "model4.set_params(**{'model__boosting_type': 'dart', 'model__colsample_bytree': 0.6000000000000001, 'model__is_unbalance': False, 'model__learning_rate': 0.5, 'model__metric': 'auc', 'model__min_child_samples': 20, 'model__n_estimators': 264, 'model__num_iterations': 1000, 'model__num_leaves': 20, 'model__verbose': 1})\n",
    "#model3.set_params(**{})\n",
    "\n",
    "estimators = [\n",
    "#    ('lr', load_model('optimised_model_Linear Regression (Ridge)_v11')),\n",
    "    ('lr', model4),\n",
    "    ('lr2', model2),\n",
    "    ('xgb', model2)\n",
    "]\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                           random_state=42)\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    X, y, random_state=42\n",
    "#)\n",
    "reg.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8895225-eb92-4e52-80cb-e531b4354617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T19:04:38.427959Z",
     "iopub.status.busy": "2023-02-05T19:04:38.427228Z",
     "iopub.status.idle": "2023-02-05T19:04:38.499475Z",
     "shell.execute_reply": "2023-02-05T19:04:38.498875Z",
     "shell.execute_reply.started": "2023-02-05T19:04:38.427927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting test data for version 06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.000000e+00, 3.000000e+00, 3.166130e-01, 5.145976e+01,\n",
       "       1.293900e-01, 3.996000e-02, 2.338100e-01, 0.000000e+00,\n",
       "       1.000000e+00, 0.000000e+00, 0.000000e+00])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    def this_test_data(VERSION, test_data_only=False, drop_nulls=True, cloud_or_webapp_run=False, versioned=False):\n",
    "        if not versioned:\n",
    "            raise AttributeError(\"need to check all calls that don't use versioned=True, and rewrite if necessary\")\n",
    "\n",
    "        suffix = \"_no_nulls\" if drop_nulls else \"\"\n",
    "\n",
    "        try:\n",
    "            if versioned:\n",
    "                print('getting test data for version', VERSION)\n",
    "                X_train = np.loadtxt(f\"../../train_test/X_train_v{VERSION}.csv\", delimiter=\",\")\n",
    "                y_train = np.loadtxt(f\"../../train_test/y_train_v{VERSION}.csv\", delimiter=\",\")\n",
    "                X_test = np.loadtxt(f\"../../train_test/X_test_v{VERSION}.csv\", delimiter=\",\")\n",
    "                y_test = np.loadtxt(f\"../../train_test/y_test_v{VERSION}.csv\", delimiter=\",\")\n",
    "                #feature_names = np.loadtxt(f\"train_test/feature_names_v{VERSION}.csv\", delimiter=\",\")\n",
    "                feature_names_str = np.genfromtxt(f\"../../train_test/feature_names_v{VERSION}.csv\",dtype='str')\n",
    "                #print(\"feature_names\")\n",
    "                #print(type(feature_names_str))\n",
    "                #print(feature_names_str)\n",
    "                #print(\"000000\", str(feature_names_str))\n",
    "                x = str(feature_names_str)\n",
    "                #print(\"x0\",type(x), x)\n",
    "                x = x[2:-2].replace(\"' '\",\" \")\n",
    "                #print(\"x1\",type(x), x)\n",
    "                feature_names = x.split(',')\n",
    "                #print(\"feature_names\",type(feature_names), feature_names)\n",
    "            elif not test_data_only:\n",
    "                print('getting suffix test data', VERSION)\n",
    "                X_train = np.loadtxt(f\"../../train_test/X_train{suffix}.csv\", delimiter=\",\")\n",
    "                y_train = np.loadtxt(f\"../../train_test/y_train{suffix}.csv\", delimiter=\",\")\n",
    "                X_test = np.loadtxt(f\"../../train_test/X_test{suffix}.csv\", delimiter=\",\")\n",
    "                y_test = np.loadtxt(f\"../../train_test/y_test{suffix}.csv\", delimiter=\",\")\n",
    "        except Exception as e:\n",
    "            print('ENDED UP IN GENERAL EXCEPTION', e)\n",
    "            print(e)\n",
    "            df, retrieval_type = get_source_dataframe(cloud_or_webapp_run=cloud_or_webapp_run, version=VERSION, folder_prefix='')\n",
    "\n",
    "            if drop_nulls:\n",
    "                df.dropna(inplace=True)\n",
    "\n",
    "            # xxxfeatures = df[df.columns[:-1]].values\n",
    "            # features = df[FEATURES].values\n",
    "            # labels = df[LABEL].values\n",
    "            # X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.9, random_state=RANDOM_STATE)\n",
    "            X_train, X_test, y_train, y_test, feature_names = tt_split(VERSION, df)\n",
    "            #print(\"feature_names\", \"feature_names\")\n",
    "\n",
    "            print('test_data_only', test_data_only)\n",
    "            print('drop_nulls', drop_nulls)\n",
    "\n",
    "            if versioned:\n",
    "                if not test_data_only:\n",
    "                    np.savetxt(f\"../../train_test/X_train_v{VERSION}.csv\", X_train, delimiter=\",\", fmt=\"%f\")\n",
    "                    np.savetxt(f\"../../train_test/y_train_v{VERSION}.csv\", y_train, delimiter=\",\", fmt=\"%f\")\n",
    "                np.savetxt(f\"../../train_test/X_test_v{VERSION}.csv\", X_test, delimiter=\",\", fmt=\"%f\")\n",
    "                np.savetxt(f\"../../train_test/y_test_v{VERSION}.csv\", y_test, delimiter=\",\", fmt=\"%f\")\n",
    "                np.savetxt(f\"../../train_test/feature_names_v{VERSION}.csv\", [feature_names], delimiter=\",\", fmt=\"%s\")\n",
    "            else:\n",
    "                if not test_data_only:\n",
    "                    suffix = '_no_nulls' if drop_nulls else ''\n",
    "                    print('suffix:', suffix)\n",
    "                    print('text:', f\"train_test/X_train{suffix}.csv\")\n",
    "                    print()\n",
    "                    print(X_train)\n",
    "                    print()\n",
    "                    np.savetxt(\"../../train_test/X_train_no_nulls.csv\", X_train, delimiter=\",\")\n",
    "                    np.savetxt(f\"../../train_test/y_train{suffix}.csv\", y_train, delimiter=\",\")\n",
    "\n",
    "                np.savetxt(f\"../../train_test/X_test{suffix}.csv\", X_test, delimiter=\",\")\n",
    "                np.savetxt(f\"../../train_test/y_test{suffix}.csv\", y_test, delimiter=\",\")\n",
    "\n",
    "        if not test_data_only:\n",
    "            return X_train, X_test, y_train, y_test, feature_names\n",
    "\n",
    "        return X_test, y_test, feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test, feature_names = this_test_data(VERSION='06', test_data_only=False, cloud_or_webapp_run=True, versioned=True)\n",
    "\n",
    "    \n",
    "X_train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
