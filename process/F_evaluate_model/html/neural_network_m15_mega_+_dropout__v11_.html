<h1>Results from Neural Network m15 mega + dropout</h1><h3>Dataset Version: 11</h3>Date run: 2023-02-04 13:57:31.962367<br>Start time: 2023-02-04 13:34:21.139932<br>End time: 2023-02-04 13:57:31.608286<br><hr><h2>Results</h2><h3>Summary</h3>saved (rather than pickled) new version of model
0.5777259911893087 is new best score (it's better than -999)<br><hr><h3>Best Model: Comparing model predictions to actual property values</h3><img src="../artifacts/neural_network_m15_mega_+_dropout__v11__best_ann_model.png"/><hr><h3>Model Specific Notes</h3>can't display hyperparameter comparison for neural network<br>can't display model performance graphs for neural network<br>can't display model performance graphs for neural network<br><hr><h3>Neural Network Loss - Head</h3><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>loss</th>
      <th>val_loss</th>
      <th>epoch</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>425120.53125</td>
      <td>425843.87500</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>424948.18750</td>
      <td>425582.43750</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>424658.15625</td>
      <td>425208.62500</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>424272.25000</td>
      <td>424828.78125</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>423801.40625</td>
      <td>424261.40625</td>
      <td>4</td>
    </tr>
  </tbody>
</table><hr><br><hr><h3>Neural Network Loss - Tail</h3><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>loss</th>
      <th>val_loss</th>
      <th>epoch</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>145</th>
      <td>48394.875000</td>
      <td>54308.980469</td>
      <td>145</td>
    </tr>
    <tr>
      <th>146</th>
      <td>48024.640625</td>
      <td>54488.632812</td>
      <td>146</td>
    </tr>
    <tr>
      <th>147</th>
      <td>47652.285156</td>
      <td>54492.296875</td>
      <td>147</td>
    </tr>
    <tr>
      <th>148</th>
      <td>47564.863281</td>
      <td>54242.980469</td>
      <td>148</td>
    </tr>
    <tr>
      <th>149</th>
      <td>47207.832031</td>
      <td>54567.992188</td>
      <td>149</td>
    </tr>
  </tbody>
</table><hr><img src="../artifacts/neural_network_m15_mega_+_dropout__v11__end_loss.png"/><hr><h3>Model Structure</h3>>Model: "sequential"
>________________________________________________________________________________________________________________________________________________________________
> Layer (type)                                                           Output Shape                                                    Param #                 
>
> normalization (Normalization)                                          (None, 83)                                                      167                     
>                                                                                                                                                                
> dense (Dense)                                                          (None, 128)                                                     10752                   
>                                                                                                                                                                
> dense_1 (Dense)                                                        (None, 256)                                                     33024                   
>                                                                                                                                                                
> batch_normalization_1 (BatchNormalization)                             (None, 256)                                                     1024                    
>                                                                                                                                                                
> activation (Activation)                                                multiple                                                        0                       
>                                                                                                                                                                
> dense_2 (Dense)                                                        (None, 512)                                                     131584                  
>                                                                                                                                                                
> batch_normalization_2 (BatchNormalization)                             (None, 512)                                                     2048                    
>                                                                                                                                                                
> dropout (Dropout)                                                      (None, 512)                                                     0                       
>                                                                                                                                                                
> dense_3 (Dense)                                                        (None, 1024)                                                    525312                  
>                                                                                                                                                                
> batch_normalization_3 (BatchNormalization)                             (None, 1024)                                                    4096                    
>                                                                                                                                                                
> dense_4 (Dense)                                                        (None, 1024)                                                    1049600                 
>                                                                                                                                                                
> dropout_1 (Dropout)                                                    (None, 1024)                                                    0                       
>                                                                                                                                                                
> batch_normalization_4 (BatchNormalization)                             (None, 1024)                                                    4096                    
>                                                                                                                                                                
> dense_5 (Dense)                                                        (None, 512)                                                     524800                  
>                                                                                                                                                                
> batch_normalization_5 (BatchNormalization)                             (None, 512)                                                     2048                    
>                                                                                                                                                                
> dense_6 (Dense)                                                        (None, 256)                                                     131328                  
>                                                                                                                                                                
> batch_normalization_6 (BatchNormalization)                             (None, 256)                                                     1024                    
>                                                                                                                                                                
> dense_7 (Dense)                                                        (None, 1)                                                       257                     
>                                                                                                                                                                
>
>Total params: 2,421,160
>Trainable params: 2,413,825
>Nontrainable params: 7,335
>________________________________________________________________________________________________________________________________________________________________
<br><hr><h2>Comparison with other models</h2><h3>Comparison with version 11 performances</h3><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>best score</th>
      <th>best time</th>
      <th>Mean Absolute Error Accuracy</th>
      <th>Mean Squared Error Accuracy</th>
      <th>R square Accuracy</th>
      <th>Root Mean Squared Error</th>
      <th>best run date</th>
      <th>best method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>neural network m15 mega + dropout (v11)</th>
      <td>0.577726</td>
      <td>1379.34</td>
      <td>53451.237498</td>
      <td>4770178490.029437</td>
      <td>0.577726</td>
      <td>69066.478772</td>
      <td>2023-02-04 13:57:28.077721</td>
      <td>loss=4.72e+04 valloss=5.37e+04 +valsplit=0.1 +patn=25 stop=150/400</td>
    </tr>
  </tbody>
</table><hr><h3>Comparison with all model performances</h3><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>best score</th>
      <th>best time</th>
      <th>Mean Absolute Error Accuracy</th>
      <th>Mean Squared Error Accuracy</th>
      <th>R square Accuracy</th>
      <th>Root Mean Squared Error</th>
      <th>best run date</th>
      <th>best method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>neural network m15 mega + dropout (v11)</th>
      <td>0.577726</td>
      <td>1379.34</td>
      <td>53451.237498</td>
      <td>4770178490.029437</td>
      <td>0.577726</td>
      <td>69066.478772</td>
      <td>2023-02-04 13:57:28.077721</td>
      <td>loss=4.72e+04 valloss=5.37e+04 +valsplit=0.1 +patn=25 stop=150/400</td>
    </tr>
  </tbody>
</table><hr><h2>Appendix</h2><h3>Data Sample</h3><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Price</th>
      <th>bedrooms</th>
      <th>bathrooms</th>
      <th>nearestStation</th>
      <th>location.latitude</th>
      <th>location.longitude</th>
      <th>latitude_deviation</th>
      <th>longitude_deviation</th>
      <th>tenure.tenureType</th>
      <th>feature__1 bedroom</th>
      <th>feature__2 bedrooms</th>
      <th>feature__2 double bedrooms</th>
      <th>feature__allocated parking</th>
      <th>feature__allocated parking space</th>
      <th>feature__balcony</th>
      <th>feature__bathroom</th>
      <th>feature__chain free</th>
      <th>feature__close to local amenities</th>
      <th>feature__communal garden</th>
      <th>feature__communal gardens</th>
      <th>feature__double bedroom</th>
      <th>feature__double glazed</th>
      <th>feature__double glazing</th>
      <th>feature__epc rating c</th>
      <th>feature__epc rating d</th>
      <th>feature__excellent location</th>
      <th>feature__excellent transport links</th>
      <th>feature__family bathroom</th>
      <th>feature__first floor</th>
      <th>feature__fitted kitchen</th>
      <th>feature__garage</th>
      <th>feature__garden</th>
      <th>feature__gas central heating</th>
      <th>feature__great location</th>
      <th>feature__ground floor</th>
      <th>feature__kitchen</th>
      <th>feature__leasehold</th>
      <th>feature__long lease</th>
      <th>feature__modern bathroom</th>
      <th>feature__modern kitchen</th>
      <th>feature__no chain</th>
      <th>feature__no onward chain</th>
      <th>feature__off street parking</th>
      <th>feature__one bedroom</th>
      <th>feature__one double bedroom</th>
      <th>feature__parking</th>
      <th>feature__private balcony</th>
      <th>feature__private garden</th>
      <th>feature__private rear garden</th>
      <th>feature__reception room</th>
      <th>feature__separate kitchen</th>
      <th>feature__share of freehold</th>
      <th>feature__three bedrooms</th>
      <th>feature__three double bedrooms</th>
      <th>feature__top floor</th>
      <th>feature__two bathrooms</th>
      <th>feature__two bedrooms</th>
      <th>feature__two double bedrooms</th>
      <th>feature__two reception rooms</th>
      <th>feature__2__garden</th>
      <th>feature__2__central heating</th>
      <th>feature__2__parking</th>
      <th>feature__2__off road</th>
      <th>feature__2__shower</th>
      <th>feature__2__cavity wall insulation</th>
      <th>feature__2__wall insulation</th>
      <th>feature__2__insulation</th>
      <th>feature__2__insulat</th>
      <th>feature__2__dining room</th>
      <th>feature__2__garage</th>
      <th>feature__2__en-suite</th>
      <th>feature__2__en suite</th>
      <th>feature__2__penthouse</th>
      <th>feature__2__balcony</th>
      <th>feature__2__double-glazing</th>
      <th>feature__2__double glazing</th>
      <th>feature__2__off-road parking</th>
      <th>feature__2__security</th>
      <th>feature__2__patio</th>
      <th>feature__2__underfloor heating</th>
      <th>feature__2__marble</th>
    </tr>
    <tr>
      <th>iddd</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>14520525</th>
      <td>550000.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>0.274316</td>
      <td>51.529950</td>
      <td>-0.207020</td>
      <td>0.030230</td>
      <td>0.102600</td>
      <td>LEASEHOLD</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>27953107</th>
      <td>400000.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>0.305845</td>
      <td>51.549390</td>
      <td>-0.482600</td>
      <td>0.049670</td>
      <td>0.378180</td>
      <td>LEASEHOLD</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>33593487</th>
      <td>579950.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.438045</td>
      <td>51.447180</td>
      <td>-0.338770</td>
      <td>0.052540</td>
      <td>0.234350</td>
      <td>FREEHOLD</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>35271294</th>
      <td>370000.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.399307</td>
      <td>51.449568</td>
      <td>-0.140154</td>
      <td>0.050152</td>
      <td>0.035734</td>
      <td>LEASEHOLD</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>44749111</th>
      <td>475000.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.410550</td>
      <td>51.370050</td>
      <td>-0.212410</td>
      <td>0.129670</td>
      <td>0.107990</td>
      <td>FREEHOLD</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table><hr><h3>Environment Variables</h3>{'notebook_environment': 'gradient', 'use_gpu': True, 'debug_mode': False, 'quick_mode': False, 'quick_override_cv_splits': 2, 'quick_override_n_iter': 10, 'quick_override_n_jobs': 3}
<hr><h3>Useful info</h3>Tensorflow version: 2.9.1<br><hr>