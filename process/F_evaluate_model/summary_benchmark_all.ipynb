{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   best score   best time  \\\nxg boost (tree) (v11)                                0.731739   71.020266   \nstacked model [knn,lgb,xgb] (v06)                    0.730645   18.923249   \nxg boost (tree) (v09)                                0.728969   89.213733   \nxg boost (tree) (v06)                                0.727132  134.174901   \nxg boost (tree) (v10)                                0.726364   69.306042   \n...                                                       ...         ...   \nneural network with autoencoding m15 mega + dro...    0.42689     1641.39   \nlinear regression (ridge) - random search (v02)      0.326879         NaN   \nlinear regression (ridge) - random search (v03)      0.326511         NaN   \nlinear regression (ridge) - random search (v04)      0.321224         NaN   \nlinear regression - basic (v01)                       0.29667         NaN   \n\n                                                   Mean Absolute Error Accuracy  \\\nxg boost (tree) (v11)                                               41595.33032   \nstacked model [knn,lgb,xgb] (v06)                                  41910.641478   \nxg boost (tree) (v09)                                              55307.269346   \nxg boost (tree) (v06)                                              42214.988358   \nxg boost (tree) (v10)                                              53862.879238   \n...                                                                         ...   \nneural network with autoencoding m15 mega + dro...                 64379.512251   \nlinear regression (ridge) - random search (v02)                     71267.87544   \nlinear regression (ridge) - random search (v03)                    70746.660452   \nlinear regression (ridge) - random search (v04)                    71834.403182   \nlinear regression - basic (v01)                                    72921.558095   \n\n                                                   Mean Squared Error Accuracy  \\\nxg boost (tree) (v11)                                        3030387686.140499   \nstacked model [knn,lgb,xgb] (v06)                            3042745935.730062   \nxg boost (tree) (v09)                                        4975738225.821958   \nxg boost (tree) (v06)                                        3096014871.208212   \nxg boost (tree) (v10)                                        4637047146.122003   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...           6474086836.603735   \nlinear regression (ridge) - random search (v02)              7702385505.171303   \nlinear regression (ridge) - random search (v03)              7492527878.209663   \nlinear regression (ridge) - random search (v04)              7712522953.793764   \nlinear regression - basic (v01)                               8297985798.70861   \n\n                                                   R square Accuracy  \\\nxg boost (tree) (v11)                                       0.731739   \nstacked model [knn,lgb,xgb] (v06)                           0.730645   \nxg boost (tree) (v09)                                       0.559529   \nxg boost (tree) (v06)                                       0.725929   \nxg boost (tree) (v10)                                       0.589511   \n...                                                              ...   \nneural network with autoencoding m15 mega + dro...           0.42689   \nlinear regression (ridge) - random search (v02)             0.326879   \nlinear regression (ridge) - random search (v03)             0.326511   \nlinear regression (ridge) - random search (v04)             0.321224   \nlinear regression - basic (v01)                              0.29667   \n\n                                                   Root Mean Squared Error  \\\nxg boost (tree) (v11)                                         55048.957176   \nstacked model [knn,lgb,xgb] (v06)                             55161.090777   \nxg boost (tree) (v09)                                         70538.912848   \nxg boost (tree) (v06)                                         55641.844606   \nxg boost (tree) (v10)                                          68095.86732   \n...                                                                    ...   \nneural network with autoencoding m15 mega + dro...            80461.710376   \nlinear regression (ridge) - random search (v02)               87763.235499   \nlinear regression (ridge) - random search (v03)               86559.389313   \nlinear regression (ridge) - random search (v04)               87820.971036   \nlinear regression - basic (v01)                               91093.280755   \n\n                                                                 best run date  \\\nxg boost (tree) (v11)                               2023-01-02 18:02:37.951724   \nstacked model [knn,lgb,xgb] (v06)                   2023-02-07 11:11:42.105711   \nxg boost (tree) (v09)                               2023-01-02 16:33:38.004418   \nxg boost (tree) (v06)                               2022-12-07 09:43:37.103009   \nxg boost (tree) (v10)                               2023-01-02 17:58:16.959076   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...  2022-12-21 01:26:33.005210   \nlinear regression (ridge) - random search (v02)                            NaN   \nlinear regression (ridge) - random search (v03)                            NaN   \nlinear regression (ridge) - random search (v04)                            NaN   \nlinear regression - basic (v01)                                            NaN   \n\n                                                                                          best method  \\\nxg boost (tree) (v11)                                                                          custom   \nstacked model [knn,lgb,xgb] (v06)                                                       random search   \nxg boost (tree) (v09)                                                                          custom   \nxg boost (tree) (v06)                                                                   random search   \nxg boost (tree) (v10)                                                                          custom   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                   best is shared  suboptimal  \nxg boost (tree) (v11)                                       False     pending  \nstacked model [knn,lgb,xgb] (v06)                           False     pending  \nxg boost (tree) (v09)                                       False  suboptimal  \nxg boost (tree) (v06)                                       False  suboptimal  \nxg boost (tree) (v10)                                       False  suboptimal  \n...                                                           ...         ...  \nneural network with autoencoding m15 mega + dro...          False     pending  \nlinear regression (ridge) - random search (v02)               NaN         NaN  \nlinear regression (ridge) - random search (v03)               NaN         NaN  \nlinear regression (ridge) - random search (v04)               NaN         NaN  \nlinear regression - basic (v01)                               NaN         NaN  \n\n[63 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>best run date</th>\n      <th>best method</th>\n      <th>best is shared</th>\n      <th>suboptimal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v11)</th>\n      <td>0.731739</td>\n      <td>71.020266</td>\n      <td>41595.33032</td>\n      <td>3030387686.140499</td>\n      <td>0.731739</td>\n      <td>55048.957176</td>\n      <td>2023-01-02 18:02:37.951724</td>\n      <td>custom</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>stacked model [knn,lgb,xgb] (v06)</th>\n      <td>0.730645</td>\n      <td>18.923249</td>\n      <td>41910.641478</td>\n      <td>3042745935.730062</td>\n      <td>0.730645</td>\n      <td>55161.090777</td>\n      <td>2023-02-07 11:11:42.105711</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>0.728969</td>\n      <td>89.213733</td>\n      <td>55307.269346</td>\n      <td>4975738225.821958</td>\n      <td>0.559529</td>\n      <td>70538.912848</td>\n      <td>2023-01-02 16:33:38.004418</td>\n      <td>custom</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>42214.988358</td>\n      <td>3096014871.208212</td>\n      <td>0.725929</td>\n      <td>55641.844606</td>\n      <td>2022-12-07 09:43:37.103009</td>\n      <td>random search</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v10)</th>\n      <td>0.726364</td>\n      <td>69.306042</td>\n      <td>53862.879238</td>\n      <td>4637047146.122003</td>\n      <td>0.589511</td>\n      <td>68095.86732</td>\n      <td>2023-01-02 17:58:16.959076</td>\n      <td>custom</td>\n      <td>False</td>\n      <td>suboptimal</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>64379.512251</td>\n      <td>6474086836.603735</td>\n      <td>0.42689</td>\n      <td>80461.710376</td>\n      <td>2022-12-21 01:26:33.005210</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>False</td>\n      <td>pending</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>0.326879</td>\n      <td>NaN</td>\n      <td>71267.87544</td>\n      <td>7702385505.171303</td>\n      <td>0.326879</td>\n      <td>87763.235499</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>0.326511</td>\n      <td>NaN</td>\n      <td>70746.660452</td>\n      <td>7492527878.209663</td>\n      <td>0.326511</td>\n      <td>86559.389313</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>0.321224</td>\n      <td>NaN</td>\n      <td>71834.403182</td>\n      <td>7712522953.793764</td>\n      <td>0.321224</td>\n      <td>87820.971036</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>0.29667</td>\n      <td>NaN</td>\n      <td>72921.558095</td>\n      <td>8297985798.70861</td>\n      <td>0.29667</td>\n      <td>91093.280755</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dff = pd.read_json('results.json')\n",
    "\n",
    "version = 'v11'\n",
    "version = 'v09'\n",
    "version = 'all'\n",
    "\n",
    "if version == 'all':\n",
    "    vNN_columns = dff.columns\n",
    "else:\n",
    "    vNN_columns = [c for c in dff.columns if version in c]\n",
    "\n",
    "dataset_versions_df = dff[vNN_columns].T.sort_values(\"best score\", ascending=False)\n",
    "dataset_versions_df_summary = dataset_versions_df[['best score', 'best time', 'Mean Absolute Error Accuracy', 'Mean Squared Error Accuracy', 'R square Accuracy', 'Root Mean Squared Error', 'best run date', 'best method', 'best is shared', \"suboptimal\"]]\n",
    "dataset_versions_df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T20:26:46.184867Z",
     "iopub.status.busy": "2023-02-06T20:26:46.184631Z",
     "iopub.status.idle": "2023-02-06T20:26:46.206318Z",
     "shell.execute_reply": "2023-02-06T20:26:46.205521Z",
     "shell.execute_reply.started": "2023-02-06T20:26:46.184846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   Mean Absolute Error Accuracy  \\\nxg boost (tree) (v11)                                               41595.33032   \nstacked model [knn,lgb,xgb] (v06)                                  41910.641478   \nxg boost (tree) (v09)                                              55307.269346   \nxg boost (tree) (v06)                                              42214.988358   \nxg boost (tree) (v10)                                              53862.879238   \n...                                                                         ...   \nneural network with autoencoding m15 mega + dro...                 64379.512251   \nlinear regression (ridge) - random search (v02)                     71267.87544   \nlinear regression (ridge) - random search (v03)                    70746.660452   \nlinear regression (ridge) - random search (v04)                    71834.403182   \nlinear regression - basic (v01)                                    72921.558095   \n\n                                                   Mean Squared Error Accuracy  \\\nxg boost (tree) (v11)                                        3030387686.140499   \nstacked model [knn,lgb,xgb] (v06)                            3042745935.730062   \nxg boost (tree) (v09)                                        4975738225.821958   \nxg boost (tree) (v06)                                        3096014871.208212   \nxg boost (tree) (v10)                                        4637047146.122003   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...           6474086836.603735   \nlinear regression (ridge) - random search (v02)              7702385505.171303   \nlinear regression (ridge) - random search (v03)              7492527878.209663   \nlinear regression (ridge) - random search (v04)              7712522953.793764   \nlinear regression - basic (v01)                               8297985798.70861   \n\n                                                   R square Accuracy  \\\nxg boost (tree) (v11)                                       0.731739   \nstacked model [knn,lgb,xgb] (v06)                           0.730645   \nxg boost (tree) (v09)                                       0.559529   \nxg boost (tree) (v06)                                       0.725929   \nxg boost (tree) (v10)                                       0.589511   \n...                                                              ...   \nneural network with autoencoding m15 mega + dro...           0.42689   \nlinear regression (ridge) - random search (v02)             0.326879   \nlinear regression (ridge) - random search (v03)             0.326511   \nlinear regression (ridge) - random search (v04)             0.321224   \nlinear regression - basic (v01)                              0.29667   \n\n                                                   Root Mean Squared Error  \\\nxg boost (tree) (v11)                                         55048.957176   \nstacked model [knn,lgb,xgb] (v06)                             55161.090777   \nxg boost (tree) (v09)                                         70538.912848   \nxg boost (tree) (v06)                                         55641.844606   \nxg boost (tree) (v10)                                          68095.86732   \n...                                                                    ...   \nneural network with autoencoding m15 mega + dro...            80461.710376   \nlinear regression (ridge) - random search (v02)               87763.235499   \nlinear regression (ridge) - random search (v03)               86559.389313   \nlinear regression (ridge) - random search (v04)               87820.971036   \nlinear regression - basic (v01)                               91093.280755   \n\n                                                                                              _method  \\\nxg boost (tree) (v11)                                                                          custom   \nstacked model [knn,lgb,xgb] (v06)                                                       random search   \nxg boost (tree) (v09)                                                 random search(pca,0.99% retain)   \nxg boost (tree) (v06)                                                                   random search   \nxg boost (tree) (v10)                                                  random search(pca,1.0% retain)   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                                                              _params  \\\nxg boost (tree) (v11)                               {'model__booster': 'dart', 'model__colsample_b...   \nstacked model [knn,lgb,xgb] (v06)                   {'model__knn1__leaf_size': 3, 'model__knn1__me...   \nxg boost (tree) (v09)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v06)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v10)                               {'model__booster': 'dart', 'model__colsample_b...   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...                      mae +epochs=400 +learn=0.0003   \nlinear regression (ridge) - random search (v02)     {'model__alpha': 1, 'model__fit_intercept': Tr...   \nlinear regression (ridge) - random search (v03)     {'model__alpha': 0.01, 'model__fit_intercept':...   \nlinear regression (ridge) - random search (v04)     {'model__alpha': 10, 'model__fit_intercept': T...   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                      _score _train time  \\\nxg boost (tree) (v11)                               0.731739   71.020266   \nstacked model [knn,lgb,xgb] (v06)                   0.730645   18.923249   \nxg boost (tree) (v09)                               0.559529   20.099668   \nxg boost (tree) (v06)                               0.725929   28.405017   \nxg boost (tree) (v10)                               0.589511    8.942586   \n...                                                      ...         ...   \nneural network with autoencoding m15 mega + dro...   0.42689     1641.39   \nlinear regression (ridge) - random search (v02)     0.326879    0.286901   \nlinear regression (ridge) - random search (v03)     0.326511    0.091898   \nlinear regression (ridge) - random search (v04)     0.321224     0.02886   \nlinear regression - basic (v01)                      0.29667    0.099876   \n\n                                                   best is shared  \\\nxg boost (tree) (v11)                                       False   \nstacked model [knn,lgb,xgb] (v06)                           False   \nxg boost (tree) (v09)                                       False   \nxg boost (tree) (v06)                                       False   \nxg boost (tree) (v10)                                       False   \n...                                                           ...   \nneural network with autoencoding m15 mega + dro...          False   \nlinear regression (ridge) - random search (v02)               NaN   \nlinear regression (ridge) - random search (v03)               NaN   \nlinear regression (ridge) - random search (v04)               NaN   \nlinear regression - basic (v01)                               NaN   \n\n                                                                                          best method  \\\nxg boost (tree) (v11)                                                                          custom   \nstacked model [knn,lgb,xgb] (v06)                                                       random search   \nxg boost (tree) (v09)                                                                          custom   \nxg boost (tree) (v06)                                                                   random search   \nxg boost (tree) (v10)                                                                          custom   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                    ...  \\\nxg boost (tree) (v11)                               ...   \nstacked model [knn,lgb,xgb] (v06)                   ...   \nxg boost (tree) (v09)                               ...   \nxg boost (tree) (v06)                               ...   \nxg boost (tree) (v10)                               ...   \n...                                                 ...   \nneural network with autoencoding m15 mega + dro...  ...   \nlinear regression (ridge) - random search (v02)     ...   \nlinear regression (ridge) - random search (v03)     ...   \nlinear regression (ridge) - random search (v04)     ...   \nlinear regression - basic (v01)                     ...   \n\n                                                                          date  \\\nxg boost (tree) (v11)                               2023-01-02 18:02:37.951724   \nstacked model [knn,lgb,xgb] (v06)                   2023-02-07 11:11:42.105711   \nxg boost (tree) (v09)                               2023-01-02 18:08:25.695144   \nxg boost (tree) (v06)                               2023-01-01 20:12:32.624731   \nxg boost (tree) (v10)                               2023-01-03 13:26:53.991141   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...  2022-12-21 01:26:33.005210   \nlinear regression (ridge) - random search (v02)     2022-10-18 23:48:02.696625   \nlinear regression (ridge) - random search (v03)     2022-10-18 23:49:36.437220   \nlinear regression (ridge) - random search (v04)     2022-10-18 23:56:43.784546   \nlinear regression - basic (v01)                     2022-10-12 12:13:28.904470   \n\n                                                                     first run  \\\nxg boost (tree) (v11)                               2022-11-30 20:18:59.880879   \nstacked model [knn,lgb,xgb] (v06)                   2023-02-07 11:11:42.105913   \nxg boost (tree) (v09)                               2022-12-14 00:46:51.092108   \nxg boost (tree) (v06)                               2022-12-03 00:21:25.848148   \nxg boost (tree) (v10)                               2023-01-02 01:31:00.393253   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...  2022-12-21 01:26:33.013203   \nlinear regression (ridge) - random search (v02)     2022-10-18 23:44:19.835809   \nlinear regression (ridge) - random search (v03)     2022-10-18 23:48:41.539572   \nlinear regression (ridge) - random search (v04)     2022-10-18 23:56:19.993042   \nlinear regression - basic (v01)                     2022-10-11 00:00:00.000000   \n\n                                                   random_state   run_env  \\\nxg boost (tree) (v11)                                       101  gradient   \nstacked model [knn,lgb,xgb] (v06)                           101  gradient   \nxg boost (tree) (v09)                                       101  gradient   \nxg boost (tree) (v06)                                       101  gradient   \nxg boost (tree) (v10)                                       101  gradient   \n...                                                         ...       ...   \nneural network with autoencoding m15 mega + dro...          101  gradient   \nlinear regression (ridge) - random search (v02)             101       NaN   \nlinear regression (ridge) - random search (v03)             101       NaN   \nlinear regression (ridge) - random search (v04)             101       NaN   \nlinear regression - basic (v01)                             101       NaN   \n\n                                                    suboptimal  \\\nxg boost (tree) (v11)                                  pending   \nstacked model [knn,lgb,xgb] (v06)                      pending   \nxg boost (tree) (v09)                               suboptimal   \nxg boost (tree) (v06)                               suboptimal   \nxg boost (tree) (v10)                               suboptimal   \n...                                                        ...   \nneural network with autoencoding m15 mega + dro...     pending   \nlinear regression (ridge) - random search (v02)            NaN   \nlinear regression (ridge) - random search (v03)            NaN   \nlinear regression (ridge) - random search (v04)            NaN   \nlinear regression - basic (v01)                            NaN   \n\n                                                                silver method  \\\nxg boost (tree) (v11)                                           random search   \nstacked model [knn,lgb,xgb] (v06)                                         NaN   \nxg boost (tree) (v09)                               rerun best: random search   \nxg boost (tree) (v06)                                           random search   \nxg boost (tree) (v10)                                                  custom   \n...                                                                       ...   \nneural network with autoencoding m15 mega + dro...                        NaN   \nlinear regression (ridge) - random search (v02)                           NaN   \nlinear regression (ridge) - random search (v03)                           NaN   \nlinear regression (ridge) - random search (v04)                           NaN   \nlinear regression - basic (v01)                                           NaN   \n\n                                                                                        silver params  \\\nxg boost (tree) (v11)                               {'model__booster': 'gbtree', 'model__early_sto...   \nstacked model [knn,lgb,xgb] (v06)                                                                 NaN   \nxg boost (tree) (v09)                               {'model__booster': 'gbtree', 'model__colsample...   \nxg boost (tree) (v06)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v10)                               {'model__booster': 'dart', 'model__colsample_b...   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...                                                NaN   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                               silver run date  \\\nxg boost (tree) (v11)                               2022-11-30 20:18:59.876471   \nstacked model [knn,lgb,xgb] (v06)                                          NaN   \nxg boost (tree) (v09)                               2023-01-02 00:28:32.774594   \nxg boost (tree) (v06)                               2022-12-03 00:21:25.790717   \nxg boost (tree) (v10)                               2023-01-02 17:32:03.977619   \n...                                                                        ...   \nneural network with autoencoding m15 mega + dro...                         NaN   \nlinear regression (ridge) - random search (v02)                            NaN   \nlinear regression (ridge) - random search (v03)                            NaN   \nlinear regression (ridge) - random search (v04)                            NaN   \nlinear regression - basic (v01)                                            NaN   \n\n                                                   silver score silver time  \nxg boost (tree) (v11)                                  0.603614   14.210391  \nstacked model [knn,lgb,xgb] (v06)                           NaN         NaN  \nxg boost (tree) (v09)                                  0.725406   28.616881  \nxg boost (tree) (v06)                                  0.725989  217.285686  \nxg boost (tree) (v10)                                   0.71985    6.836689  \n...                                                         ...         ...  \nneural network with autoencoding m15 mega + dro...          NaN         NaN  \nlinear regression (ridge) - random search (v02)             NaN         NaN  \nlinear regression (ridge) - random search (v03)             NaN         NaN  \nlinear regression (ridge) - random search (v04)             NaN         NaN  \nlinear regression - basic (v01)                             NaN         NaN  \n\n[63 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean Absolute Error Accuracy</th>\n      <th>Mean Squared Error Accuracy</th>\n      <th>R square Accuracy</th>\n      <th>Root Mean Squared Error</th>\n      <th>_method</th>\n      <th>_params</th>\n      <th>_score</th>\n      <th>_train time</th>\n      <th>best is shared</th>\n      <th>best method</th>\n      <th>...</th>\n      <th>date</th>\n      <th>first run</th>\n      <th>random_state</th>\n      <th>run_env</th>\n      <th>suboptimal</th>\n      <th>silver method</th>\n      <th>silver params</th>\n      <th>silver run date</th>\n      <th>silver score</th>\n      <th>silver time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v11)</th>\n      <td>41595.33032</td>\n      <td>3030387686.140499</td>\n      <td>0.731739</td>\n      <td>55048.957176</td>\n      <td>custom</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.731739</td>\n      <td>71.020266</td>\n      <td>False</td>\n      <td>custom</td>\n      <td>...</td>\n      <td>2023-01-02 18:02:37.951724</td>\n      <td>2022-11-30 20:18:59.880879</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>pending</td>\n      <td>random search</td>\n      <td>{'model__booster': 'gbtree', 'model__early_sto...</td>\n      <td>2022-11-30 20:18:59.876471</td>\n      <td>0.603614</td>\n      <td>14.210391</td>\n    </tr>\n    <tr>\n      <th>stacked model [knn,lgb,xgb] (v06)</th>\n      <td>41910.641478</td>\n      <td>3042745935.730062</td>\n      <td>0.730645</td>\n      <td>55161.090777</td>\n      <td>random search</td>\n      <td>{'model__knn1__leaf_size': 3, 'model__knn1__me...</td>\n      <td>0.730645</td>\n      <td>18.923249</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2023-02-07 11:11:42.105711</td>\n      <td>2023-02-07 11:11:42.105913</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>pending</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>55307.269346</td>\n      <td>4975738225.821958</td>\n      <td>0.559529</td>\n      <td>70538.912848</td>\n      <td>random search(pca,0.99% retain)</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.559529</td>\n      <td>20.099668</td>\n      <td>False</td>\n      <td>custom</td>\n      <td>...</td>\n      <td>2023-01-02 18:08:25.695144</td>\n      <td>2022-12-14 00:46:51.092108</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>suboptimal</td>\n      <td>rerun best: random search</td>\n      <td>{'model__booster': 'gbtree', 'model__colsample...</td>\n      <td>2023-01-02 00:28:32.774594</td>\n      <td>0.725406</td>\n      <td>28.616881</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>42214.988358</td>\n      <td>3096014871.208212</td>\n      <td>0.725929</td>\n      <td>55641.844606</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.725929</td>\n      <td>28.405017</td>\n      <td>False</td>\n      <td>random search</td>\n      <td>...</td>\n      <td>2023-01-01 20:12:32.624731</td>\n      <td>2022-12-03 00:21:25.848148</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>suboptimal</td>\n      <td>random search</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>2022-12-03 00:21:25.790717</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v10)</th>\n      <td>53862.879238</td>\n      <td>4637047146.122003</td>\n      <td>0.589511</td>\n      <td>68095.86732</td>\n      <td>random search(pca,1.0% retain)</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>0.589511</td>\n      <td>8.942586</td>\n      <td>False</td>\n      <td>custom</td>\n      <td>...</td>\n      <td>2023-01-03 13:26:53.991141</td>\n      <td>2023-01-02 01:31:00.393253</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>suboptimal</td>\n      <td>custom</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>2023-01-02 17:32:03.977619</td>\n      <td>0.71985</td>\n      <td>6.836689</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>64379.512251</td>\n      <td>6474086836.603735</td>\n      <td>0.42689</td>\n      <td>80461.710376</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>False</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>...</td>\n      <td>2022-12-21 01:26:33.005210</td>\n      <td>2022-12-21 01:26:33.013203</td>\n      <td>101</td>\n      <td>gradient</td>\n      <td>pending</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>71267.87544</td>\n      <td>7702385505.171303</td>\n      <td>0.326879</td>\n      <td>87763.235499</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 1, 'model__fit_intercept': Tr...</td>\n      <td>0.326879</td>\n      <td>0.286901</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:48:02.696625</td>\n      <td>2022-10-18 23:44:19.835809</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>70746.660452</td>\n      <td>7492527878.209663</td>\n      <td>0.326511</td>\n      <td>86559.389313</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 0.01, 'model__fit_intercept':...</td>\n      <td>0.326511</td>\n      <td>0.091898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:49:36.437220</td>\n      <td>2022-10-18 23:48:41.539572</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>71834.403182</td>\n      <td>7712522953.793764</td>\n      <td>0.321224</td>\n      <td>87820.971036</td>\n      <td>NaN</td>\n      <td>{'model__alpha': 10, 'model__fit_intercept': T...</td>\n      <td>0.321224</td>\n      <td>0.02886</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-18 23:56:43.784546</td>\n      <td>2022-10-18 23:56:19.993042</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>72921.558095</td>\n      <td>8297985798.70861</td>\n      <td>0.29667</td>\n      <td>91093.280755</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.29667</td>\n      <td>0.099876</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2022-10-12 12:13:28.904470</td>\n      <td>2022-10-11 00:00:00.000000</td>\n      <td>101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_versions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-06T20:26:46.207325Z",
     "iopub.status.busy": "2023-02-06T20:26:46.207101Z",
     "iopub.status.idle": "2023-02-06T20:26:46.218347Z",
     "shell.execute_reply": "2023-02-06T20:26:46.217637Z",
     "shell.execute_reply.started": "2023-02-06T20:26:46.207299Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   best score   best time  \\\nxg boost (tree) (v11)                                0.731739   71.020266   \nstacked model [knn,lgb,xgb] (v06)                    0.730645   18.923249   \nxg boost (tree) (v09)                                0.728969   89.213733   \nxg boost (tree) (v06)                                0.727132  134.174901   \nxg boost (tree) (v10)                                0.726364   69.306042   \n...                                                       ...         ...   \nneural network with autoencoding m15 mega + dro...    0.42689     1641.39   \nlinear regression (ridge) - random search (v02)      0.326879         NaN   \nlinear regression (ridge) - random search (v03)      0.326511         NaN   \nlinear regression (ridge) - random search (v04)      0.321224         NaN   \nlinear regression - basic (v01)                       0.29667         NaN   \n\n                                                   silver score silver time  \\\nxg boost (tree) (v11)                                  0.603614   14.210391   \nstacked model [knn,lgb,xgb] (v06)                           NaN         NaN   \nxg boost (tree) (v09)                                  0.725406   28.616881   \nxg boost (tree) (v06)                                  0.725989  217.285686   \nxg boost (tree) (v10)                                   0.71985    6.836689   \n...                                                         ...         ...   \nneural network with autoencoding m15 mega + dro...          NaN         NaN   \nlinear regression (ridge) - random search (v02)             NaN         NaN   \nlinear regression (ridge) - random search (v03)             NaN         NaN   \nlinear regression (ridge) - random search (v04)             NaN         NaN   \nlinear regression - basic (v01)                             NaN         NaN   \n\n                                                                                          best method  \\\nxg boost (tree) (v11)                                                                          custom   \nstacked model [knn,lgb,xgb] (v06)                                                       random search   \nxg boost (tree) (v09)                                                                          custom   \nxg boost (tree) (v06)                                                                   random search   \nxg boost (tree) (v10)                                                                          custom   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...  loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                                silver method  \\\nxg boost (tree) (v11)                                           random search   \nstacked model [knn,lgb,xgb] (v06)                                         NaN   \nxg boost (tree) (v09)                               rerun best: random search   \nxg boost (tree) (v06)                                           random search   \nxg boost (tree) (v10)                                                  custom   \n...                                                                       ...   \nneural network with autoencoding m15 mega + dro...                        NaN   \nlinear regression (ridge) - random search (v02)                           NaN   \nlinear regression (ridge) - random search (v03)                           NaN   \nlinear regression (ridge) - random search (v04)                           NaN   \nlinear regression - basic (v01)                                           NaN   \n\n                                                   best is shared  \nxg boost (tree) (v11)                                       False  \nstacked model [knn,lgb,xgb] (v06)                           False  \nxg boost (tree) (v09)                                       False  \nxg boost (tree) (v06)                                       False  \nxg boost (tree) (v10)                                       False  \n...                                                           ...  \nneural network with autoencoding m15 mega + dro...          False  \nlinear regression (ridge) - random search (v02)               NaN  \nlinear regression (ridge) - random search (v03)               NaN  \nlinear regression (ridge) - random search (v04)               NaN  \nlinear regression - basic (v01)                               NaN  \n\n[63 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best method</th>\n      <th>silver method</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v11)</th>\n      <td>0.731739</td>\n      <td>71.020266</td>\n      <td>0.603614</td>\n      <td>14.210391</td>\n      <td>custom</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>stacked model [knn,lgb,xgb] (v06)</th>\n      <td>0.730645</td>\n      <td>18.923249</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>random search</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>0.728969</td>\n      <td>89.213733</td>\n      <td>0.725406</td>\n      <td>28.616881</td>\n      <td>custom</td>\n      <td>rerun best: random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n      <td>random search</td>\n      <td>random search</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v10)</th>\n      <td>0.726364</td>\n      <td>69.306042</td>\n      <td>0.71985</td>\n      <td>6.836689</td>\n      <td>custom</td>\n      <td>custom</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>loss=6.51e+04 valloss=6.52e+04 +valsplit=0.1 +...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>0.326879</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>0.326511</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>0.321224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>0.29667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_1_vs_2 = dataset_versions_df[['best score', 'best time', 'silver score', 'silver time', 'best method', 'silver method', 'best is shared']]\n",
    "df_summary_1_vs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-02-06T20:26:46.220234Z",
     "iopub.status.busy": "2023-02-06T20:26:46.219683Z",
     "iopub.status.idle": "2023-02-06T20:26:46.233627Z",
     "shell.execute_reply": "2023-02-06T20:26:46.232821Z",
     "shell.execute_reply.started": "2023-02-06T20:26:46.220213Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   best score   best time  \\\nxg boost (tree) (v11)                                0.731739   71.020266   \nstacked model [knn,lgb,xgb] (v06)                    0.730645   18.923249   \nxg boost (tree) (v09)                                0.728969   89.213733   \nxg boost (tree) (v06)                                0.727132  134.174901   \nxg boost (tree) (v10)                                0.726364   69.306042   \n...                                                       ...         ...   \nneural network with autoencoding m15 mega + dro...    0.42689     1641.39   \nlinear regression (ridge) - random search (v02)      0.326879         NaN   \nlinear regression (ridge) - random search (v03)      0.326511         NaN   \nlinear regression (ridge) - random search (v04)      0.321224         NaN   \nlinear regression - basic (v01)                       0.29667         NaN   \n\n                                                   silver score silver time  \\\nxg boost (tree) (v11)                                  0.603614   14.210391   \nstacked model [knn,lgb,xgb] (v06)                           NaN         NaN   \nxg boost (tree) (v09)                                  0.725406   28.616881   \nxg boost (tree) (v06)                                  0.725989  217.285686   \nxg boost (tree) (v10)                                   0.71985    6.836689   \n...                                                         ...         ...   \nneural network with autoencoding m15 mega + dro...          NaN         NaN   \nlinear regression (ridge) - random search (v02)             NaN         NaN   \nlinear regression (ridge) - random search (v03)             NaN         NaN   \nlinear regression (ridge) - random search (v04)             NaN         NaN   \nlinear regression - basic (v01)                             NaN         NaN   \n\n                                                                                          best params  \\\nxg boost (tree) (v11)                               {'model__booster': 'dart', 'model__colsample_b...   \nstacked model [knn,lgb,xgb] (v06)                   {'model__knn1__leaf_size': 3, 'model__knn1__me...   \nxg boost (tree) (v09)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v06)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v10)                               {'model__booster': 'dart', 'model__colsample_b...   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...                      mae +epochs=400 +learn=0.0003   \nlinear regression (ridge) - random search (v02)                                MULTIPLE PARAM OPTIONS   \nlinear regression (ridge) - random search (v03)                                MULTIPLE PARAM OPTIONS   \nlinear regression (ridge) - random search (v04)                                MULTIPLE PARAM OPTIONS   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                                                        silver params  \\\nxg boost (tree) (v11)                               {'model__booster': 'gbtree', 'model__early_sto...   \nstacked model [knn,lgb,xgb] (v06)                                                                 NaN   \nxg boost (tree) (v09)                               {'model__booster': 'gbtree', 'model__colsample...   \nxg boost (tree) (v06)                               {'model__booster': 'dart', 'model__colsample_b...   \nxg boost (tree) (v10)                               {'model__booster': 'dart', 'model__colsample_b...   \n...                                                                                               ...   \nneural network with autoencoding m15 mega + dro...                                                NaN   \nlinear regression (ridge) - random search (v02)                                                   NaN   \nlinear regression (ridge) - random search (v03)                                                   NaN   \nlinear regression (ridge) - random search (v04)                                                   NaN   \nlinear regression - basic (v01)                                                                   NaN   \n\n                                                   best is shared  \nxg boost (tree) (v11)                                       False  \nstacked model [knn,lgb,xgb] (v06)                           False  \nxg boost (tree) (v09)                                       False  \nxg boost (tree) (v06)                                       False  \nxg boost (tree) (v10)                                       False  \n...                                                           ...  \nneural network with autoencoding m15 mega + dro...          False  \nlinear regression (ridge) - random search (v02)               NaN  \nlinear regression (ridge) - random search (v03)               NaN  \nlinear regression (ridge) - random search (v04)               NaN  \nlinear regression - basic (v01)                               NaN  \n\n[63 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>best score</th>\n      <th>best time</th>\n      <th>silver score</th>\n      <th>silver time</th>\n      <th>best params</th>\n      <th>silver params</th>\n      <th>best is shared</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>xg boost (tree) (v11)</th>\n      <td>0.731739</td>\n      <td>71.020266</td>\n      <td>0.603614</td>\n      <td>14.210391</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>{'model__booster': 'gbtree', 'model__early_sto...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>stacked model [knn,lgb,xgb] (v06)</th>\n      <td>0.730645</td>\n      <td>18.923249</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'model__knn1__leaf_size': 3, 'model__knn1__me...</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v09)</th>\n      <td>0.728969</td>\n      <td>89.213733</td>\n      <td>0.725406</td>\n      <td>28.616881</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>{'model__booster': 'gbtree', 'model__colsample...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v06)</th>\n      <td>0.727132</td>\n      <td>134.174901</td>\n      <td>0.725989</td>\n      <td>217.285686</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>xg boost (tree) (v10)</th>\n      <td>0.726364</td>\n      <td>69.306042</td>\n      <td>0.71985</td>\n      <td>6.836689</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>{'model__booster': 'dart', 'model__colsample_b...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>neural network with autoencoding m15 mega + dropout (v09)</th>\n      <td>0.42689</td>\n      <td>1641.39</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>mae +epochs=400 +learn=0.0003</td>\n      <td>NaN</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v02)</th>\n      <td>0.326879</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v03)</th>\n      <td>0.326511</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression (ridge) - random search (v04)</th>\n      <td>0.321224</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>MULTIPLE PARAM OPTIONS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>linear regression - basic (v01)</th>\n      <td>0.29667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_vs_2b = dataset_versions_df[['best score', 'best time', 'silver score', 'silver time', 'best params', 'silver params', 'best is shared']]\n",
    "df_1_vs_2b\n",
    "#{'model__booster': 'gbtree', 'model__early_stopping_rounds': None, 'model__gamma': 100, 'model__learning_rate': None, 'model__max_delta_step': 0, 'model__max_depth': 6, 'model__min_child_weight': ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
